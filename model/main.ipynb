{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f9adec9-dc0c-4380-a1bb-e83dc4a58870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.41.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\long\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\long\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-lightning) (1.26.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-lightning) (2.3.1+cpu)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\long\\appdata\\roaming\\python\\python311\\site-packages (from pytorch-lightning) (4.66.2)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.6.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-lightning) (1.4.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-lightning) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-lightning) (4.9.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-lightning) (0.11.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (65.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->pytorch-lightning) (3.15.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->pytorch-lightning) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->pytorch-lightning) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->pytorch-lightning) (3.1.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->pytorch-lightning) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning) (0.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2.0.0->pytorch-lightning) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2.0.0->pytorch-lightning) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=2.0.0->pytorch-lightning) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=2.0.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\long\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install pytorch-lightning\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0ee81ff-57e2-4b05-be27-45bc525afb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./dataset/processed/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b014ea-16c9-4e7a-9c0d-a42fce3f9a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>59848</td>\n",
       "      <td>this is so cool. it is like, 'would you want y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>59849</td>\n",
       "      <td>thank you!! this would make my life a lot less...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>59852</td>\n",
       "      <td>this is such an urgent design problem; kudos t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>59855</td>\n",
       "      <td>is this something i will be able to install on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>59856</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                       comment_text  score\n",
       "0           0  59848  this is so cool. it is like, 'would you want y...      0\n",
       "1           1  59849  thank you!! this would make my life a lot less...      0\n",
       "2           2  59852  this is such an urgent design problem; kudos t...      0\n",
       "3           3  59855  is this something i will be able to install on...      0\n",
       "4           4  59856               haha you guys are a bunch of losers.      9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv(data_path, dtype={\"id\": str})\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91546f99-ebdd-4aed-b08a-45c5e20ac2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_token_len = ds[\"comment_text\"].str.len().max() + 2\n",
    "max_token_len = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02a31d36-2aa3-4e80-bb0c-893e7df315e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          this is so cool. it is like, 'would you want y...\n",
       "1          thank you!! this would make my life a lot less...\n",
       "2          this is such an urgent design problem; kudos t...\n",
       "3          is this something i will be able to install on...\n",
       "4                       haha you guys are a bunch of losers.\n",
       "                                 ...                        \n",
       "1964286    \":::::and for the second time of asking, when ...\n",
       "1964287    you should be ashamed of yourself \\n\\nthat is ...\n",
       "1964288    spitzer \\n\\numm, there is no actual article fo...\n",
       "1964289    and it looks like it was actually you who put ...\n",
       "1964290    \"\\nand ... i really do not think you understan...\n",
       "Name: comment_text, Length: 1964291, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = ds[\"comment_text\"]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f685f96c-8449-40f6-ab5f-0dc0f6bfa0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          9\n",
       "          ..\n",
       "1964286    0\n",
       "1964287    0\n",
       "1964288    0\n",
       "1964289    0\n",
       "1964290    0\n",
       "Name: score, Length: 1964291, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = ds[\"score\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9de208a3-04a6-4e79-989a-540df59beca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e76dcb75-e552-468f-b6d9-0fa903fc1b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>519999</th>\n",
       "      <td>interesting how the democrat liberals turn the...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892924</th>\n",
       "      <td>ban\\nit was only for six months that ban is ov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115773</th>\n",
       "      <td>i do not know of too many men who are publicly...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759297</th>\n",
       "      <td>i wonder if you called for the imprisonment of...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745627</th>\n",
       "      <td>pam smith has been a sycophantic party gadfly ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783558</th>\n",
       "      <td>and because politicians have houses\\nthey can ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194361</th>\n",
       "      <td>mr. trump has exceeded his first amendment pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662299</th>\n",
       "      <td>\"it is a unique forum that newspapers offer. i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662739</th>\n",
       "      <td>i think we too are the people who, on the one ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309769</th>\n",
       "      <td>try to stay on topic, focus, get back on your ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1571432 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment_text  score\n",
       "519999   interesting how the democrat liberals turn the...      8\n",
       "1892924  ban\\nit was only for six months that ban is ov...      0\n",
       "1115773  i do not know of too many men who are publicly...      0\n",
       "759297   i wonder if you called for the imprisonment of...      2\n",
       "1745627  pam smith has been a sycophantic party gadfly ...      0\n",
       "...                                                    ...    ...\n",
       "783558   and because politicians have houses\\nthey can ...      0\n",
       "194361   mr. trump has exceeded his first amendment pro...      0\n",
       "1662299  \"it is a unique forum that newspapers offer. i...      2\n",
       "1662739  i think we too are the people who, on the one ...      3\n",
       "1309769  try to stay on topic, focus, get back on your ...      8\n",
       "\n",
       "[1571432 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = pd.DataFrame({\"comment_text\": X_train, \"score\": y_train})\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff0bde25-5d53-4b2b-9dbc-a7969b275cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1539379</th>\n",
       "      <td>now that we got that out of the way, can we st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143896</th>\n",
       "      <td>the only fraud in this picture is trump himself.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268050</th>\n",
       "      <td>liberals have to come to grips with the fact t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84155</th>\n",
       "      <td>lying?  it was a facebook post?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885782</th>\n",
       "      <td>thanks, delicious carbuncle. this admission, h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423548</th>\n",
       "      <td>[right could have ironically benefited today f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496621</th>\n",
       "      <td>the comments by these doctors that there are m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989732</th>\n",
       "      <td>the answer to this question is self evident. \\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809035</th>\n",
       "      <td>hi judyrae, well, it is been 7 years now, and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696727</th>\n",
       "      <td>this season began and ended with the offensive...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392859 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment_text  score\n",
       "1539379  now that we got that out of the way, can we st...      0\n",
       "1143896   the only fraud in this picture is trump himself.      0\n",
       "1268050  liberals have to come to grips with the fact t...      0\n",
       "84155                      lying?  it was a facebook post?      0\n",
       "1885782  thanks, delicious carbuncle. this admission, h...      0\n",
       "...                                                    ...    ...\n",
       "1423548  [right could have ironically benefited today f...      0\n",
       "496621   the comments by these doctors that there are m...      0\n",
       "989732   the answer to this question is self evident. \\...      0\n",
       "809035   hi judyrae, well, it is been 7 years now, and ...      0\n",
       "1696727  this season began and ended with the offensive...      0\n",
       "\n",
       "[392859 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds = pd.DataFrame({\"comment_text\": X_test, \"score\": y_test})\n",
    "val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4361aca-f24e-463b-a7c0-3b6e61578a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8a405cd-334f-4f7a-b6d8-eb4d181d4590",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicityDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_token_len, sample = 700_000):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = int(max_token_len)\n",
    "        self.sample = sample\n",
    "        self.__prepare_data()\n",
    "\n",
    "    def __prepare_data(self):\n",
    "        if self.sample is not None:\n",
    "            toxic = self.data.loc[self.data[\"score\"] > 0]\n",
    "            not_toxic = self.data.loc[self.data[\"score\"] == 0]\n",
    "            self.data = pd.concat([toxic, not_toxic.sample(self.sample, random_state=53)])\n",
    "            print(self.data.head())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index > len(self.data):\n",
    "            raise IndexError(\"Index out of bound: \", f\"index: {index}, len: {len(self.data)}\")\n",
    "        item = self.data.iloc[index]\n",
    "        comment = str(item.comment_text)\n",
    "        score = torch.tensor(item.iloc[1], dtype=torch.float32)\n",
    "        # score = torch.FloatTensor(item[[\"score\"]])\n",
    "        \n",
    "        tokens = self.tokenizer.encode_plus(comment,\n",
    "                                           add_special_tokens=True,\n",
    "                                           return_tensors=\"pt\",\n",
    "                                           truncation=True,\n",
    "                                           max_length=self.max_token_len,\n",
    "                                           padding=\"max_length\",\n",
    "                                           return_attention_mask=True)\n",
    "\n",
    "        return {\"input_ids\": tokens.input_ids.flatten(), \"attention_mask\": tokens.attention_mask.flatten(), \"label\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8508544-4750-4e83-b3d7-10d2bcf15289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              comment_text  score\n",
      "519999   interesting how the democrat liberals turn the...      8\n",
      "759297   i wonder if you called for the imprisonment of...      2\n",
      "477418   we all have the ability to hate, just look at ...      2\n",
      "1588926  terrorist attack on canadian soil...no comment...      2\n",
      "1031047  subjective guilt has never been relevant to th...      5\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "train_dataset = ToxicityDataset(train_ds, tokenizer, max_token_len)\n",
    "val_dataset = ToxicityDataset(val_ds, tokenizer, max_token_len, sample=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "713a12ce-9b26-47e5-8ee4-86b1fbf7ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dc221ab-16db-44de-9fe5-b8b6b1369db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicityDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_data, val_data, max_token_len, model_name, batch_size):\n",
    "        super().__init__()\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_len = max_token_len\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def setup(self, stage = \"fit\"):\n",
    "        if stage == \"fit\":\n",
    "            self.train_ds = ToxicityDataset(self.train_data, self.tokenizer, max_token_len)\n",
    "            self.val_ds = ToxicityDataset(self.val_data, self.tokenizer, max_token_len, sample=None)\n",
    "        if stage == \"predict\":\n",
    "            self.val_ds = ToxicityDataset(self.val_data, self.tokenizer, max_token_len, sample=None)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_size = self.batch_size, num_workers=7, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size = self.batch_size, num_workers=4, shuffle=False)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size = self.batch_size, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54fa055a-3511-499f-ad30-4f126d6910b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AdamW, get_cosine_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torchmetrics.functional.classification import auroc\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c87eb05a-5d76-4872-af55-0660fd36e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicityClassifier(pl.LightningModule):\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.pretrained_model = AutoModel.from_pretrained(config[\"model_name\"])\n",
    "        # hidden layer\n",
    "        self.hidden = nn.Linear(self.pretrained_model.config.hidden_size, self.pretrained_model.config.hidden_size)\n",
    "        # classification layer\n",
    "        self.classifier = nn.Linear(self.pretrained_model.config.hidden_size, self.config[\"n_labels\"])\n",
    "        torch.nn.init.xavier_uniform_(self.hidden.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
    "        self.loss_func = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, label=None):\n",
    "        # roberta model\n",
    "        output = self.pretrained_model(input_ids = input_ids, attention_mask = attention_mask)\n",
    "        pooled_output = torch.mean(output.last_hidden_state, 1)\n",
    "        # nerual network classfication layer\n",
    "        pooled_output = self.hidden(pooled_output)\n",
    "        # activation function\n",
    "        pooled_output = F.relu(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = 0\n",
    "\n",
    "        if label is not None:\n",
    "            loss = self.loss_func(logits.view(-1, self.config[\"n_labels\"]), label.view(-1, self.config['n_labels']))\n",
    "            return loss, logits\n",
    "\n",
    "    def training_step(self, batch, batch_index):\n",
    "        loss, logits = self(**batch)\n",
    "        self.log(\"train loss\", loss, prog_bar = True, logger = True)\n",
    "        return { \"loss\": loss, \"predictions\": logits, \"label\": batch[\"label\"]}\n",
    "\n",
    "    def validation_step(self, batch, batch_index):\n",
    "        loss, logits = self(**batch)\n",
    "        self.log(\"validation loss\", loss, prog_bar = True, logger = True)\n",
    "        return { \"val_loss\": loss, \"predictions\": logits, \"label\": batch[\"label\"]}\n",
    "\n",
    "    def prediction_step(self, batch, batch_index):\n",
    "        _, logits = self(**batch)\n",
    "        return logits\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.config[\"lr\"], weight_decay=self.config[\"w_decay\"])\n",
    "        # optimizer = AdamW(self.parameters(), lr=self.config[\"lr\"], weight_decay=self.config[\"w_decay\"])\n",
    "        total_steps = self.config[\"train_size\"] / self.config[\"batch_size\"]\n",
    "        warmup_steps = math.floor(total_steps + self.config[\"warmup\"])\n",
    "        scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "        return [optimizer], [scheduler]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6de778c-1dd1-4b9f-bde5-1dc7c91d7d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              comment_text  score\n",
      "519999   interesting how the democrat liberals turn the...      8\n",
      "759297   i wonder if you called for the imprisonment of...      2\n",
      "477418   we all have the ability to hate, just look at ...      2\n",
      "1588926  terrorist attack on canadian soil...no comment...      2\n",
      "1031047  subjective guilt has never been relevant to th...      5\n"
     ]
    }
   ],
   "source": [
    "data_module = ToxicityDataModule(train_ds, val_ds, max_token_len, model_name = \"roberta-base\", batch_size=128)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "380a8017-4514-4387-a5cb-c5f4592041f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model_name\": \"distilroberta-base\",\n",
    "    \"n_labels\": 1,\n",
    "    \"batch_size\": 128,\n",
    "    \"lr\": 1.5e-6,\n",
    "    \"warmup\": 0.2,\n",
    "    \"train_size\": len(data_module.train_dataloader()) ,\n",
    "    \"w_decay\": 0.001,\n",
    "    \"n_epochs\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05c4ee5f-337c-4103-a6f9-cf314704ea26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              comment_text  score\n",
      "519999   interesting how the democrat liberals turn the...      8\n",
      "759297   i wonder if you called for the imprisonment of...      2\n",
      "477418   we all have the ability to hate, just look at ...      2\n",
      "1588926  terrorist attack on canadian soil...no comment...      2\n",
      "1031047  subjective guilt has never been relevant to th...      5\n"
     ]
    }
   ],
   "source": [
    "data_module = ToxicityDataModule(train_ds, val_ds, max_token_len, model_name = config[\"model_name\"], batch_size = config[\"batch_size\"])\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bba54dfd-b4e6-4618-b293-495ec9c46075",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ToxicityClassifier(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20c9217c-e7df-4dc0-b441-abf50e5dd687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.)\n",
      "torch.Size([]) torch.Size([1, 1]) tensor([[1.0777]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "idx=0\n",
    "input_ids = train_dataset.__getitem__(idx)['input_ids']\n",
    "attention_mask = train_dataset.__getitem__(idx)['attention_mask']\n",
    "label = train_dataset.__getitem__(idx)['label']\n",
    "model.cpu()\n",
    "print(label)\n",
    "loss, output = model(input_ids.unsqueeze(dim=0), attention_mask.unsqueeze(dim=0), label.unsqueeze(dim=0))\n",
    "print(label.shape, output.shape, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b1a81d-1bf8-4f8d-a3cd-d7b80762b8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | pretrained_model | RobertaModel     | 82.1 M | eval \n",
      "1 | hidden           | Linear           | 590 K  | train\n",
      "2 | classifier       | Linear           | 769    | train\n",
      "3 | loss_func        | CrossEntropyLoss | 0      | train\n",
      "4 | dropout          | Dropout          | 0      | train\n",
      "--------------------------------------------------------------\n",
      "82.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "82.7 M    Total params\n",
      "330.839   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              comment_text  score\n",
      "519999   interesting how the democrat liberals turn the...      8\n",
      "759297   i wonder if you called for the imprisonment of...      2\n",
      "477418   we all have the ability to hate, just look at ...      2\n",
      "1588926  terrorist attack on canadian soil...no comment...      2\n",
      "1031047  subjective guilt has never been relevant to th...      5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3e7f12db1a472cbba09677d229d583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                           | 0/? [00:00<?, ?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    trainer = pl.Trainer(max_epochs=config[\"n_epochs\"], num_sanity_val_steps=2, logger = True, enable_progress_bar = True, num_nodes = 1)\n",
    "    trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788a7417-a8e3-453e-a734-8da5ec888552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbdef03-4a62-4104-a5a7-a35ddcb807ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc64b552-bad8-49e3-b149-fb006e80a622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
